{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parse:\n",
    "    id_pattern = re.compile(r'\\/id\\/([0-9]+)')\n",
    "    sequence_pattern = re.compile(r'sequence=([0-9]+)')\n",
    "    author_pattern = re.compile(r'([a-z][A-Z])')\n",
    "\n",
    "    @staticmethod\n",
    "    def ID(href):\n",
    "        return Parse.id_pattern.search(href).group(1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def authors(author):\n",
    "        return \"; \".join(Parse.author_pattern.split(author))\n",
    "        \n",
    "    @staticmethod\n",
    "    def html(html):\n",
    "        soup = BeautifulSoup(html)\n",
    "        return html\n",
    "    \n",
    "    @staticmethod\n",
    "    def sequence(href):\n",
    "        return int(Parse.sequence_pattern.search(href).group(1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_filename(filename):\n",
    "        ID, sequence = filename.split('-')\n",
    "        return ID, int(sequence)\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_sequence(sequence, hrefs):\n",
    "        for i in range(len(hrefs)):\n",
    "            href = hrefs[i]\n",
    "            if sequence == Parse.sequence(href):\n",
    "                return i + 1\n",
    "        return sequence\n",
    "        \n",
    "\n",
    "def load_metadata(metadata_path):\n",
    "    metadata = dict()\n",
    "    \n",
    "    # load metadata from json\n",
    "    with open(metadata_path, \"r\") as file:\n",
    "        database = json.load(file)\n",
    "    # index entries with id\n",
    "    for i in database:\n",
    "        key = Parse.ID(i[\"href\"])\n",
    "        metadata[key] = i\n",
    "    return metadata\n",
    "\n",
    "def dataset(zipfile, metadata):\n",
    "    res = []\n",
    "    pattern = re.compile(r'\\.html?')\n",
    "    for filename in tqdm(zipfile.namelist()):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        \n",
    "        # filter out unwanted extension\n",
    "        if pattern.match(ext) is None:\n",
    "            continue\n",
    "            \n",
    "        # recover news id and file index\n",
    "        ID, sequence = Parse.split_filename(name)\n",
    "        # properties with news id\n",
    "        properties = metadata[ID]\n",
    "        \n",
    "\n",
    "        if sequence > len(properties[\"files\"]) or sequence != Parse.sequence(properties[\"files\"][sequence-1][\"href\"]):\n",
    "            sequence = Parse.find_sequence(sequence, [file[\"href\"] for file in properties[\"files\"]])  \n",
    "        # append tuple with the necessary informations\n",
    "        file_properties = properties[\"files\"][sequence-1]   \n",
    "        res.append((name, zipfile.read(filename).decode('utf-8','replace'), properties[\"title\"], Parse.authors(properties[\"author\"]), properties[\"href\"], properties[\"citation\"], properties[\"date\"], file_properties[\"name\"],file_properties[\"size\"], file_properties[\"filetype\"], file_properties[\"href\"]))\n",
    "\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "archieves = [('globo-2020-7.zip','globo-2020-7.json'),('estado-de-sao-paulo-2020-7.zip','estado-de-sao-paulo-2020-7.json'),('valor-economico-2020-7.zip','valor-economico-2020-7.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89601/89601 [00:04<00:00, 18477.81it/s]\n",
      "100%|██████████| 111415/111415 [00:06<00:00, 18047.70it/s]\n",
      "100%|██████████| 59095/59095 [00:03<00:00, 16079.33it/s]\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "dfs = []\n",
    "for archive in archieves:\n",
    "    archive_path = os.path.join(cwd, 'data', archive[0])\n",
    "    metadata_path = os.path.join(cwd, 'data', archive[1])\n",
    "    metadata = load_metadata(metadata_path)\n",
    "    # load zipfile\n",
    "    zipfile = ZipFile(archive_path)\n",
    "    # create list with files and informations\n",
    "    files = dataset(zipfile, metadata)\n",
    "    \n",
    "    df = pd.DataFrame(files, columns=[\"id\", \"html\", \"title\", \"author\", \"href\", \"citation\", \"date\", \"filename\", \"filesize\", \"filetype\", \"filehref\"])\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.concat(dfs, ignore_index=True, keys=None, levels=None, names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.to_csv(\"news.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
